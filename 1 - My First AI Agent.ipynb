{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My First AI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<center><img src=\"./images/time_agent.png\" width=\"600\"/></center>\n",
    "</div>\n",
    "\n",
    "In this exercise, you will use [**LangGraph**](https://www.langchain.com/langgraph) and its [`create_react_agent`](https://langchain-ai.github.io/langgraph/reference/prebuilt/) utility function to build a ReAct AI agent with a simple yet specific task: **providing the current date and time in a specific location**. This agent will respond to questions such as:\n",
    "\n",
    "**\"What time is it in Italy?\"**\n",
    "\n",
    "To achieve this, the agent will follow these steps:\n",
    "1. Understand the task the user wants it to perform.\n",
    "2. Map the user-provided location to its corresponding timezone using its internal knowledge.\n",
    "3. Use a tool to retrieve the current date and time for that timezone.\n",
    "4. Generate a response based on the tool's output to answer the userâ€™s query.\n",
    "\n",
    "This exercise will give you hands-on experience with **LangGraph** and the process of building AI agents equipped with reasoning and tool-using capabilities.\n",
    "\n",
    "Letâ€™s get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparing the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the AI agent, we need to set up our environment and import the necessary functions and libraries. In this exercise, we will use:\n",
    "\n",
    "- [`load_dotenv`](https://pypi.org/project/python-dotenv/): To load environment variables (e.g., your OpenAI API key).\n",
    "- [`ChatOpenAI`](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html): A language model interface for interacting with OpenAI's GPT models.\n",
    "- [`create_react_agent`](https://langchain-ai.github.io/langgraph/reference/prebuilt/): A utility from **LangGraph** for building ReAct AI agents.\n",
    "- [`tool`](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html): A decorator to define tools that the agent can use during execution.\n",
    "- `print_stream`: A utility to print the agentâ€™s responses as they stream in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from utils.stream import print_stream\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initializing the Large Language Model (LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to create a new AI Agent with LangGraph is to initialize the OpenAI language model that our agent will use to process and respond to queries. When specifying the model, it's a good practice to:\n",
    "\n",
    "1. **Specify the full model name**: To ensure compatibility and stability (e.g., `gpt-4o-mini-2024-07-18`).\n",
    "2. **Start with a low temperature value**: A temperature of `0` ensures deterministic responses, making the agent focus on precision. You can increase the temperature later for more creative responses.\n",
    "\n",
    "For this exercise, we will use the latest version of the `gpt-4o-mini` model (`gpt-4o-mini-2024-07-18`) with a temperature of `0`, but you can experiment with other models (the full list is available [here](https://platform.openai.com/docs/models#current-model-aliases)), temperatures, and other parameters to see how they affect the agent's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"openai:gpt-4o-mini-2024-07-18\"\n",
    "MODEL_TEMPERATURE = 0\n",
    "\n",
    "llm = init_chat_model(model=MODEL_NAME, temperature=MODEL_TEMPERATURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about ChatOpenAI in the official langchain documentation: https://python.langchain.com/docs/integrations/chat/openai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before equipping our agent with tools, letâ€™s verify that the underlying language model lacks access to real-time information such as the current date and time. This is expected behavior because the LLM operates on static knowledge and does not have tools or APIs to fetch live data on its own.\n",
    "\n",
    "Weâ€™ll confirm this by asking the LLM the following question:  \n",
    "\n",
    "**\"What time is it in Italy?\"**\n",
    "\n",
    "Letâ€™s run the code and observe the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can learn more about langchain messages and roles in the official documentation: https://python.langchain.com/docs/concepts/messages/\n",
    "messages = [\n",
    "    (\"user\", \"What time is it in Italy?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(\"Assistant:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen that the LLM cannot access real-time information on its own, we can give the AI agent a **tool** to fill this gap. Tools are external functions that the agent can use to assist in answering user queries.\n",
    "\n",
    "### Tool Requirements:\n",
    "\n",
    "For this exercise, we are building a tool to retrieve the current date and time for a given timezone. Here's what the tool should do:\n",
    "1. Accept an input, specifically a timezone.\n",
    "2. Determine the current date and time for that timezone.\n",
    "3. Return the result to the agent.\n",
    "4. Manage any errors that may occur during the process.\n",
    "\n",
    "You can define your own implementation of the tool (recomended) or use the provided one.\n",
    "\n",
    "To learn more about tools in LangGraph, you can refer to the official documentation: https://python.langchain.com/docs/concepts/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.date_and_time import prebuilt_get_current_datetime\n",
    "\n",
    "@tool\n",
    "def get_current_datetime(timezone: str) -> str:\n",
    "    \"\"\"TODO: Use this space to describe this tool to the agent.\n",
    "    Try to answer the following questions:\n",
    "        - What does this tool do?\n",
    "        - What is the input?\n",
    "        - How should the input be formatted?\n",
    "    You can also provide examples of how to use this tool to help the agent understand it better.\n",
    "    \"\"\"\n",
    "    #TODO Implement the function logic here or use the prebuilt version\n",
    "    # return prebuilt_get_current_datetime(timezone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the tool by calling it with a sample timezone, such as `\"Europe/Rome\"`, and observe the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_datetime.invoke(\"Europe/Rome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crafting the Agent System Prompt\n",
    "\n",
    "Before integrating tools and building our agent, we need to define the **system prompt**. The system prompt acts as the foundation for the agent's behavior by clearly outlining its role, purpose, instructions, and limitations.\n",
    "\n",
    "Crafting the perfect system prompt is an iterative process, so you can start with a simple version and refine it as you test the agent's performance.\n",
    "\n",
    "### Prompt Engineering Techniques:\n",
    "Here are some techniques to keep in mind when defining the agent's system prompt:\n",
    "1. **Role Prompting**: Clearly define the role of the agent (e.g., \"You are D&T Bot, an agent specialized in providing the current date and time for different locations.\").\n",
    "2. [**Few-Shot Prompting**](https://www.promptingguide.ai/techniques/fewshot) (Optional): Provide a few examples of user questions and the appropriate responses to guide the agent further.\n",
    "\n",
    "You can learn more about prompt engineering in the prompting engineering guide: [https://www.promptingguide.ai/](https://www.promptingguide.ai/)\n",
    "\n",
    "### Your Task:\n",
    "Define a system prompt for your agent. The agent should:\n",
    "- Clearly convey its **role and purpose**.\n",
    "- Provide the **current date and time** for a specific location when asked.\n",
    "- Ask the user to specify a location if it is not provided.\n",
    "- Politely decline to answer any queries unrelated to date and time.\n",
    "\n",
    "### Things to Consider:\n",
    "- **No Need to Describe Tools**: You do not need to specify the tools or their behaviors in the system prompt. The agent will already know how to use them based on the descriptions you provided earlier.\n",
    "- **Be Creative**: You can inject some personality into your prompt if desired to give your agent a unique tone (e.g., friendly, formal, or professional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_AND_TIME_AGENT_PROMPT = \"\"\"\"#TODO: Define your agent system prompt here.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building the AI Agent\n",
    "\n",
    "Now that we have all the core components ready:\n",
    "1. The **language model (LLM)** for processing queries.\n",
    "2. A **tool** for retrieving the current date and time.\n",
    "3. A well-crafted **system prompt** to guide the agent's behavior.\n",
    "\n",
    "Weâ€™re ready to bring everything together into a fully functional AI agent. \n",
    "\n",
    "### How It Works:\n",
    "Weâ€™ll use the **`create_react_agent`** function from LangGraph. This utility embeds the logic required to create a basic **ReAct (Reason + Act)** agent, allowing it to:\n",
    "- Reason about the userâ€™s query.\n",
    "- Decide whether and how to use the provided tools.\n",
    "- Generate meaningful responses, respecting the constraints of the system prompt.\n",
    "\n",
    "### Key Parameters:\n",
    "- **`model`**: The LLM we defined earlier.\n",
    "- **`tools`**: A list of tools (e.g., the `get_current_datetime` tool).\n",
    "- **`prompt`**: The system prompt crafted to guide the agent.\n",
    "\n",
    "You can learn more about the `create_react_agent` function in the official LangGraph documentation: https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(model=llm, tools=[get_current_datetime], prompt=DATE_AND_TIME_AGENT_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ReAct agent** we just created isn't just a simple function; it's a structured graph that represents how the agent reasons, acts, and responds to user input. LangGraph allows us to visualize this graph, which helps us better understand:\n",
    "- How the agent processes inputs.\n",
    "- How its decision-making workflow is structured.\n",
    "\n",
    "Letâ€™s display the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing the AI Agent\n",
    "\n",
    "Now that the agent is fully built, it's time to test it! By sending a query to the agent, we can examine how it:\n",
    "1. Processes the input question.\n",
    "2. Reasonably decides if and how to use tools like `get_current_datetime`.\n",
    "3. Produces an accurate and user-friendly response.\n",
    "\n",
    "### Testing Query:\n",
    "Letâ€™s try the same query we used to test the LLM:\n",
    "\n",
    "**\"What time is it in Italy?\"**\n",
    "\n",
    "To verify that the agent is now capable of providing the current date and time for a specific location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"What time is it in Italy?\"\"\"\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", question)]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a more complex query:\n",
    "\n",
    "**\"What time is it in Italy and California?\"**\n",
    "\n",
    "This query is intentionally a little tricky so we can observe how the agent handles both locations and whether it uses tools appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"What time is it in Italy and California?\"\"\"\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", question)]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Testing:\n",
    "\n",
    "Now that your agent is up and running, itâ€™s time to test it with your own queries! This hands-on testing allows you to evaluate:\n",
    "1. **How well the agent responds to expected queries** (e.g., asking the time in different locations).\n",
    "2. **Whether it handles unexpected or ambiguous queries gracefully** (e.g., if no location is provided or irrelevant questions are asked).\n",
    "3. **How effectively it uses the tools** to fulfill its purpose.\n",
    "\n",
    "### Iterative Process:\n",
    "\n",
    "Crafting the perfect agent is an **iterative process**. Use these trials to identify areas of improvement and adjust the agent as needed. Consider modifying the following aspects:\n",
    "- **System Prompt**: Adjust the wording to clarify the agentâ€™s purpose, add reasoning steps, or inject personality.\n",
    "- **Tool Definition**: Rename tools, change their parameters, or improve their descriptions for clarity and better integration.\n",
    "- **Model Settings**: Experiment with model temperature to balance determinism (`temperature=0`) and creativity (higher values).\n",
    "- **Tool Limitations**: For example, add error handling if an invalid timezone is passed.\n",
    "\n",
    "### Tips for Effective Refinement:\n",
    "- If your agent isnâ€™t responding as expected, start by reviewing the reasoning traces and the tool execution steps.\n",
    "- Test with a wider variety of queries to account for edge cases.\n",
    "- Iterate gradually, making small adjustments to prompts, tools, or configurations one step at a time.\n",
    "\n",
    "Remember, building an AI agent is like sculptingâ€”it evolves over time with refinement and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"<YOUR QUESTION HERE>\"\"\"\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", question)]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Observing the Agent's Reasoning\n",
    "\n",
    "For educational purposes, it can be helpful to make a ReAct AI agent **explicitly explain its reasoning steps**. This allows us to:\n",
    "1. **Understand how the agent thinks**: By viewing its intermediate reasoning steps, we can better grasp how the agent interprets the question and makes decisions.\n",
    "2. **Debug issues interactively**: If the agent doesnâ€™t perform as expected, we can identify exactly where its reasoning or tool usage went wrong.\n",
    "3. **Reinforce Prompt Engineering**: Small changes in the system prompt can significantly affect the agent's behavior. Testing these changes provides insight into how to fine-tune prompts for specific workflows.\n",
    "\n",
    "To force the agent to 'think out loud', we can tell it to do so using a specific system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLICIT_DATE_AND_TIME_REACT_AGENT_PROMPT = \"You are a ReAct agent. Explicitly state the reasoning before each tool call. #TODO: Define the rest of your agent system prompt here.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.system import SystemMessage\n",
    "\n",
    "explicit_graph = create_react_agent(model=llm, tools=[get_current_datetime], prompt=EXPLICIT_DATE_AND_TIME_REACT_AGENT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"What time is it in Italy and California?\"\"\"\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", question)]}\n",
    "\n",
    "print_stream(explicit_graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Add Short Term Memory to the Agent\n",
    "\n",
    "Until now, our agent operates in a **stateless mode**, meaning it processes each query independently without any awareness of previous interactions. For example, if you ask the agent:\n",
    "\n",
    "- *\"What is the last thing I asked you?\"*\n",
    "\n",
    "The agent will fail to respond meaningfully because it doesn't retain previous conversation history.\n",
    "\n",
    "### Why Add Memory?\n",
    "\n",
    "Adding **memory** enables the agent to:\n",
    "1. **Support multi-turn conversations**: It will remember context from earlier queries and use that information in future responses.\n",
    "2. **Improve user experience**: This creates a more natural, conversational flow, where the agent can track and respond to follow-up questions or clarifications.\n",
    "3. **Enable full conversational applications**: With memory, the agent can handle ongoing interactions without asking repetitive questions or losing track of the dialogue.\n",
    "\n",
    "You can learn more about memory in LangGraph in the official documentation: https://langchain-ai.github.io/langgraph/how-tos/persistence/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Initialize MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph_with_memory = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[get_current_datetime],\n",
    "    prompt=DATE_AND_TIME_AGENT_PROMPT,\n",
    "    checkpointer=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid4()) # The thread_id is a unique identifier for each conversation thread.\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"What time is it in Italy?\"\"\"\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", question)]}\n",
    "\n",
    "print_stream(graph_with_memory.stream(inputs,  config, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"What is the last question I asked you?\"\"\"\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", question)]}\n",
    "\n",
    "print_stream(graph_with_memory.stream(inputs, config, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "ðŸŽ‰ Congratulations on Completing the exercise! ðŸŽ‰\n",
    "\n",
    "Well done! You've successfully built your first AI agent using **LangGraph** and explored its capabilities step by step. \n",
    "\n",
    "### What Weâ€™ve Accomplished:\n",
    "1. **Understanding Stateless Assistants**: You saw how an LLM alone cannot provide real-time information without tools or resources.\n",
    "2. **Defining Tools**: You created a custom tool to retrieve the current date and time for specific time zones using Python and LangGraph's `@tool` decorator.\n",
    "3. **Crafting a System Prompt**: Using prompt engineering, you wrote clear instructions for the agent to guide its reasoning and behavior.\n",
    "4. **Building the Agent**: Using `create_react_agent`, you orchestrated the `LLM`, tools, and system prompt into a fully functional ReAct AI agent.\n",
    "5. **Testing and Refining**: You tested the agent with sample queries, refined its behavior with explicit reasoning, and enabled multi-turn conversations by incorporating **memory**.\n",
    "\n",
    "### Whatâ€™s Next?\n",
    "\n",
    "Youâ€™re now ready to move to the **next notebook**! In the second exercise, youâ€™ll deepen your understanding of LangGraph by:\n",
    "- Exploring more advanced tools and functionalities.\n",
    "- Building a more complex agent with additional reasoning and decision-making capabilities.\n",
    "\n",
    "Head over to Notebook \"**2 - My Second AI Agent.ipynb**\" to continue your journey and build upon the foundational knowledge you've gained here.\n",
    "\n",
    "ðŸš€ Keep up the amazing work, and letâ€™s make your next agent even smarter!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
